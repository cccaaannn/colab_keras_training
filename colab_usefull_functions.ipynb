{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_usefull_functions",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cccaaannn/deep_learning_colab/blob/master/colab_usefull_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVAQ7iY9W6fj",
        "colab_type": "text"
      },
      "source": [
        "functions for using drive with colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-QUgnQaW_rP",
        "colab_type": "text"
      },
      "source": [
        "creating different size training data folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBYMR017W5o_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from distutils.dir_util import copy_tree\n",
        "import os\n",
        "index = 0\n",
        "for i,folder in enumerate(os.listdir(\"/content/drive/My Drive/Datalar100_2\")):\n",
        "  if(folder not in os.listdir(\"/content/drive/My Drive/data30\") and folder != \".DS_Store\"):\n",
        "    if(index<50):\n",
        "      index += 1\n",
        "      copy_tree(\"/content/drive/My Drive/Datalar100_2/\"+folder,\"/content/drive/My Drive/data50/\"+folder)\n",
        "      print(index)\n",
        "    else:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuVNPG67XHXI",
        "colab_type": "text"
      },
      "source": [
        "dividing training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dlnRB6mXKH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "from shutil import copyfile\n",
        "main_dir = \"/content/drive/My Drive/Datalar100_2\"\n",
        "\n",
        "folders = os.listdir(main_dir)\n",
        "folders.remove(\".DS_Store\")\n",
        "test_path = os.path.join(main_dir,\"test\")\n",
        "train_path = os.path.join(main_dir,\"train\")\n",
        "os.makedirs(test_path)\n",
        "os.makedirs(train_path)\n",
        "\n",
        "\n",
        "for i,folder in enumerate(folders):\n",
        "  try:\n",
        "    print(i)\n",
        "    current_test_folder = os.path.join(test_path,folder)\n",
        "    current_train_folder = os.path.join(train_path,folder)\n",
        "    os.makedirs(current_test_folder)\n",
        "    os.makedirs(current_train_folder)\n",
        "    for index, image in enumerate(os.listdir(os.path.join(main_dir,folder))):\n",
        "        current_img = os.path.join(main_dir,folder,image)\n",
        "        if(index<15):\n",
        "            copyfile(current_img,os.path.join(current_test_folder,image))\n",
        "        else:\n",
        "            copyfile(current_img,os.path.join(current_train_folder,image))\n",
        "  except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wSToaKxZ58q",
        "colab_type": "text"
      },
      "source": [
        "**select tf 1.x**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK2CCKSfZ5sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cdgmp1FyVd_",
        "colab_type": "text"
      },
      "source": [
        "**keras imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwMgo7r5yVFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# keras and tf\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "# models\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "\n",
        "# backend\n",
        "from keras import optimizers, metrics, models\n",
        "import keras.backend as K\n",
        "\n",
        "# layers\n",
        "from keras.layers import Input, add, Conv2D, Flatten, Dense, Dropout, Activation\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D, BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "# optimizers\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# regularizers\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# training\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
        "\n",
        "# save\n",
        "import h5py\n",
        "\n",
        "# keras aplications\n",
        "from keras.applications import DenseNet201, DenseNet169, InceptionResNetV2, ResNet152V2, InceptionV3, DenseNet121, Xception, MobileNet, VGG19\n",
        "\n",
        "\n",
        "# other libs\n",
        "import math\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKoMRxfdXtaH",
        "colab_type": "text"
      },
      "source": [
        "**keras image data generator**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osWYsDGJXwA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        # rotation -40 40\n",
        "        rotation_range=40,\n",
        "\n",
        "        # shift images and fill pixels with nearest\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        fill_mode='nearest',\n",
        "\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.2,\n",
        "\n",
        "        shear_range=0.2,\n",
        "\n",
        "        brightness_range=[0.1, 0.5],\n",
        "        channel_shift_range=0.5,\n",
        "\n",
        "        # normalization \n",
        "        featurewise_center=True,\n",
        "        featurewise_std_normalization=True,\n",
        "        # validation_split=0.2,\n",
        "        )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "\n",
        "# train = train_datagen.flow_from_directory(\"/content/drive/My Drive/Data/train\", shuffle=True, class_mode='categorical', target_size=(image_size,image_size), batch_size=batch_size)\n",
        "# valid = valid_datagen.flow_from_directory(\"/content/drive/My Drive/Data/test\", shuffle=True, class_mode='categorical', target_size=(image_size,image_size), batch_size=batch_size)\n",
        "\n",
        "train = valid_datagen.flow_from_directory(\"/content/drive/My Drive/clean_data/train\", target_size=(image_size,image_size), batch_size=batch_size)\n",
        "valid = valid_datagen.flow_from_directory(\"/content/drive/My Drive/clean_data/test\", target_size=(image_size,image_size), batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-IIvNgAZ04N",
        "colab_type": "text"
      },
      "source": [
        "**convert model to sequential and add last layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCSohYpCZ0d9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "for layer in base_model.layers:\n",
        "    model.add(layer)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(100, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRN0EF9tarPn",
        "colab_type": "text"
      },
      "source": [
        "**optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upMKNYkwaq1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = SGD(lr=0.001, momentum=0.9)\n",
        "opt = Adam(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS-I2hBIaHvJ",
        "colab_type": "text"
      },
      "source": [
        "**model checkpointer and learning schedular**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5IkQIFXaILu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = \"/content/drive/My Drive/model\"\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath= model_path+'-{epoch:02d}-{val_loss:0.5f}-{val_accuracy:0.5f}.hdf5', verbose=1, monitor='val_loss', save_best_only=True)\n",
        "\n",
        "def schedule(epoch):\n",
        "    if epoch < 15:\n",
        "        return 0.001\n",
        "    elif epoch < 20:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(schedule)\n",
        "\n",
        "history = model.fit_generator(train, epochs=100, verbose=1, validation_data=valid, callbacks=[lr_scheduler, checkpointer])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}